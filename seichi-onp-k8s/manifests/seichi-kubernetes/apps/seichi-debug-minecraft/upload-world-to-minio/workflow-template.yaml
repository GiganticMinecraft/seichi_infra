apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: upload-world-to-minio
  namespace: seichi-debug-minecraft
  annotations:
    workflows.argoproj.io/description: "最新PBSバックアップからワールドデータを抽出し、Garageにアップロードするワークフロー"
spec:
  serviceAccountName: upload-world-to-minio-workflow-sa
  ttlStrategy:
    secondsAfterCompletion: 86400
  activeDeadlineSeconds: 7200 # 2時間でタイムアウト（リストア+圧縮+アップロードに時間がかかる可能性）
  entrypoint: default
  templates:
    - name: default
      steps:
        - - name: restore-and-upload-s1
            template: restore-and-upload
            arguments:
              parameters:
                - name: server-name
                  value: "s1"
        - - name: cleanup-after-s1
            template: cleanup
        - - name: restore-and-upload-s2
            template: restore-and-upload
            arguments:
              parameters:
                - name: server-name
                  value: "s2"

    - name: cleanup
      script:
        image: debian:13
        command: ["/bin/sh", "-c"]
        source: |
          echo "=== Cleaning up work directory ==="
          rm -rf /work/restore /work/pbs-cache /work/*.tar.zst
          echo "Cleanup complete"
        volumeMounts:
          - name: work-volume
            mountPath: /work

    - name: restore-and-upload
      inputs:
        parameters:
          - name: server-name
      script:
        image: debian:13
        command: ["/bin/sh", "-c"]
        source: |
          set -e

          rm -rf /work/restore /work/pbs-cache
          mkdir -p /work/restore /work/pbs-cache

          echo "=== Installing proxmox-backup-client ==="
          apt update
          apt install -y curl zstd python3

          echo "Adding Proxmox Backup Client repository..."
          echo "deb http://download.proxmox.com/debian/pbs-client trixie main" > /etc/apt/sources.list.d/pbs-client.list
          curl -fsSL https://enterprise.proxmox.com/debian/proxmox-release-trixie.gpg -o /etc/apt/trusted.gpg.d/proxmox-release-trixie.gpg

          apt update
          apt install -y proxmox-backup-client=4.0.14-1

          echo "=== Finding latest {{inputs.parameters.server-name}} snapshot ==="
          LATEST_SNAPSHOT=$(proxmox-backup-client snapshot list \
            --repository "${PBS_USER}@${PBS_HOST}:${PBS_DATASTORE}" \
            --output-format json \
            | python3 -c "
          import json, sys, datetime
          snapshots = json.load(sys.stdin)
          s1_snapshots = [s for s in snapshots if s['backup-id'] == 'mcserver--{{inputs.parameters.server-name}}']
          if not s1_snapshots:
              print('No mcserver--{{inputs.parameters.server-name}} snapshots found', file=sys.stderr)
              sys.exit(1)
          latest = max(s1_snapshots, key=lambda s: s['backup-time'])
          ts = datetime.datetime.fromtimestamp(latest['backup-time'], tz=datetime.timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')
          print(f\"host/mcserver--{{inputs.parameters.server-name}}/{ts}\")
          ")
          echo "Latest snapshot: ${LATEST_SNAPSHOT}"

          echo "=== Restoring world directories from PBS ==="
          proxmox-backup-client restore "${LATEST_SNAPSHOT}" \
            data.pxar /work/restore \
            --repository "${PBS_USER}@${PBS_HOST}:${PBS_DATASTORE}" \
            --pattern '/world_*/**' \
            --pattern '/world_*'

          echo "=== Restore contents ==="
          ls -la /work/restore/

          echo "=== Installing AWS CLI ==="
          apt install -y unzip
          curl -fsSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "/tmp/awscliv2.zip"
          unzip -q /tmp/awscliv2.zip -d /tmp
          /tmp/aws/install
          rm -rf /tmp/awscliv2.zip /tmp/aws

          echo "=== Compressing and uploading each world ==="
          WORLD_NAMES="world_2 world_2_the_end world_SW world_SW_2 world_SW_3 world_SW_4 world_SW_nether world_SW_the_end"

          for WORLD_NAME in $WORLD_NAMES; do
            WORLD_DIR="/work/restore/${WORLD_NAME}"
            if [ ! -d "$WORLD_DIR" ]; then
              echo "WARNING: ${WORLD_NAME} not found in backup, skipping"
              continue
            fi

            FILENAME="${WORLD_NAME}.tar.zst"

            echo "--- Compressing ${WORLD_NAME} ---"
            tar cf - -C "$WORLD_DIR" . | zstd -o "/work/tmp-${FILENAME}"
            echo "Compressed file size: $(du -h /work/tmp-${FILENAME} | cut -f1)"

            echo "--- Uploading ${WORLD_NAME} ---"
            aws --endpoint-url http://garage.garage.svc.cluster.local:3900 --region seichi-cloud s3 cp "/work/tmp-${FILENAME}" "s3://mc-worlds/{{inputs.parameters.server-name}}/${FILENAME}"
            echo "Uploaded: mc-worlds/{{inputs.parameters.server-name}}/${FILENAME}"

            rm -f "/work/tmp-${FILENAME}"
          done

          echo "=== All worlds uploaded ==="
        env:
          - name: TZ
            value: "Asia/Tokyo"
          - name: PBS_USER
            valueFrom:
              secretKeyRef:
                name: pbs-credentials
                key: user
          - name: PBS_HOST
            valueFrom:
              secretKeyRef:
                name: pbs-credentials
                key: host
          - name: PBS_DATASTORE
            valueFrom:
              secretKeyRef:
                name: pbs-credentials
                key: datastore
          - name: PBS_PASSWORD
            valueFrom:
              secretKeyRef:
                name: pbs-credentials
                key: password
          - name: PBS_FINGERPRINT
            valueFrom:
              secretKeyRef:
                name: pbs-credentials
                key: fingerprint
          - name: AWS_ACCESS_KEY_ID
            valueFrom:
              secretKeyRef:
                name: garage-s3-credentials
                key: AWS_ACCESS_KEY_ID
          - name: AWS_SECRET_ACCESS_KEY
            valueFrom:
              secretKeyRef:
                name: garage-s3-credentials
                key: AWS_SECRET_ACCESS_KEY
        volumeMounts:
          - name: work-volume
            mountPath: /work
          # /root/.cache が overlayfs 配下だとスクリプトがこけるので O_TMPFILE フラグ付きの openat(2) が実行可能なファイルシステムをマウントする
          # refs: https://gist.github.com/unchama/0922fce3c490e46b6f9e822f4377853e
          - name: work-volume
            mountPath: /root/.cache
            subPath: pbs-cache
  # NOTE: 本当はエフェメラルボリュームにしたかったが、ワールドデータが巨大すぎてできなかったので PVC を使用している
  volumeClaimTemplates:
    - metadata:
        name: work-volume
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 80Gi
