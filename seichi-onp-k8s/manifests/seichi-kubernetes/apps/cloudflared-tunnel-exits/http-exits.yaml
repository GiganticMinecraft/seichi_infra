apiVersion: argoproj.io/v1alpha1
kind: ApplicationSet
metadata:
  name: cloudflared-tunnel-http-exits
  namespace: argocd
spec:
  generators:
    - list:
        # 出口を生成するリスト。
        # オンプレネットワーク内で HTTP で公開されているサービスを外部に露出したい時は、
        # このリストに
        #   - トンネル名の suffix として使われる文字列 (name)
        #   - 露出されるサービスが外部から見えるようになるドメイン (external-hostname)
        #   - Pod から見た、サービスが公開されている authority ({{domain-name}}:{{port}} の形式の文字列) (internal-authority)
        # の三つのプロパティを持つ要素を追加すればよい。
        elements:
          # k8s 上の Grafana。
          # grafana側でGitHub-SSO認証が掛かっているため、Cloudflare のレイヤではアクセス制御はしていない。
          - name: grafana-k8s
            external-hostname: grafana.onp-k8s.admin.seichi.click
            internal-authority: "prometheus-grafana.monitoring:80"

          # オンプレにもともとあった Grafana。
          # grafana側でGitHub-SSO認証が掛かっているため、Cloudflare のレイヤではアクセス制御はしていない。
          - name: grafana-onp
            external-hostname: grafana.onp.admin.seichi.click
            internal-authority: "192.168.3.20:3000"

          # プライベートなminecraft pluginをアップロードするためのMinIO。
          # 肝心のオブジェクトストレージは seichi-private-plugin-blackhole-minio.minio:9000 にClusterIPでアクセスすればよい。
          - name: minio-console
            external-hostname: minio-console.onp-k8s.admin.seichi.click
            internal-authority: "seichi-private-plugin-blackhole-minio-console.minio:9001"

          # Cilium HubbleのUI
          - name: hubble-ui
            external-hostname: hubble-ui.onp-k8s.admin.seichi.click
            internal-authority: "hubble-ui.kube-system:80"

          # seichi-timed-stats 用 InfluxDB のUI (管理用)
          # 特に制限は掛けていないため、 /api/v2 で API を叩くこともできる
          - name: timed-stats-influxdb
            external-hostname: seichi-timed-stats-influxdb-ui.onp-k8s.admin.seichi.click
            internal-authority: "seichi-timed-stats-influxdb-influxdb2.seichi-minecraft:8086"

          # 各サーバーの Dynmap ウェブサーバー
          - name: dynmap-s1
            external-hostname: s1.map.gigantic.seichi.click
            internal-authority: "192.168.2.1:80"
          - name: dynmap-s2
            external-hostname: s2.map.gigantic.seichi.click
            internal-authority: "192.168.2.2:80"
          - name: dynmap-s3
            external-hostname: s3.map.gigantic.seichi.click
            internal-authority: "192.168.2.3:80"
          - name: dynmap-s5
            external-hostname: s5.map.gigantic.seichi.click
            internal-authority: "192.168.2.5:80"
          - name: dynmap-s7
            external-hostname: s7.map.gigantic.seichi.click
            internal-authority: "192.168.2.7:80"
          - name: dynmap-cre
            external-hostname: cre.map.gigantic.seichi.click
            internal-authority: "192.168.1.187:80"
          - name: dynmap-h1
            external-hostname: h1.map.spring.seichi.click
            internal-authority: "192.168.1.187:82"

          # SeichiRanking の web サーバー。
          - name: seichi-ranking
            external-hostname: ranking-gigantic.seichi.click
            internal-authority: "192.168.3.1:80"
  template:
    metadata:
      name: "cloudflared-tunnel-http-exit--{{name}}"
      namespace: argocd
    spec:
      project: cloudflared-tunnel-exits
      source:
        repoURL: https://giganticminecraft.github.io/seichi_infra
        chart: cloudflared-tunnel
        targetRevision: "1.0.3"
        helm:
          # サービス一つに対してトンネルを一つずつ生やす
          releaseName: cloudflared-tunnel-http-exit--{{name}}
          values: |
            installationName: {{name}}
            tunnelNamePrefix: "seichi-onp-k8s--http--"
            tunnelCredentialSecretName: "cloudflared-tunnel-credential"
            tunnelConfigContent: |
              ingress:
                - hostname: {{external-hostname}}
                  service: "http://{{internal-authority}}"
                # Catch-all service
                - service: http_status:404

      destination:
        server: https://kubernetes.default.svc
        namespace: cloudflared-tunnel-exits
      syncPolicy:
        automated:
          prune: true
          selfHeal: true
          allowEmpty: true
        retry:
          limit: -1
          backoff:
            duration: 5s
            factor: 2
            maxDuration: 2m
