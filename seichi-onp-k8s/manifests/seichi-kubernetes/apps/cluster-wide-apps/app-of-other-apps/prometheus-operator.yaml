apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: prometheus
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io # cascade deletion on this App deletion
spec:
  project: cluster-wide-apps
  source:
    chart: kube-prometheus-stack
    repoURL: https://prometheus-community.github.io/helm-charts
    targetRevision: 82.4.3
    helm:
      releaseName: prometheus
      skipCrds: false
      values: |
        defaultRules:
          create: true
          rules:
            kubeProxy: false
            alertmanager: false
            windows: false
        prometheus-windows-exporter:
          prometheus:
            monitor:
              enabled: false
        kubelet:
          serviceMonitor:
            attachMetadata:
              node: true
        nodeExporter:
          operatingSystems:
            darwin:
              enabled: false
        loki:
          isDefault: false
        grafana:
          sidecar:
            datasources:
              enabled: false
              defaultDatasourceEnabled: false
              isDefaultDatasource: false
            dashboards:
              enabled: true
              defaultFolderName: ""
              label: grafana_dashboard
              labelValue: "1"
              folderAnnotation: grafana_folder
              searchNamespace: ALL
              provider:
                foldersFromFilesStructure: true
          defaultDashboardsTimezone: Asia/Tokyo
          plugins:
            - isovalent-hubble-datasource
            - grafana-sentry-datasource
          grafana.ini:
            log:
              level: warn
            server:
              enforce_domain: true
              domain: grafana.onp-k8s.admin.seichi.click
              root_url: https://%(domain)s/
            date_formats:
              default_timezone: Asia/Tokyo
            auth:
              disable_login_form: true
            auth.github:
              enabled: true
              allow_sign_up: true
              auto_login: true
              client_id: $__env{GF_AUTH_GITHUB_CLIENT_ID}
              client_secret: $__env{GF_AUTH_GITHUB_CLIENT_SECRET}
              scopes: user:email,read:org
              auth_url: https://github.com/login/oauth/authorize
              token_url: https://github.com/login/oauth/access_token
              api_url: https://api.github.com/user
              allowed_organizations: GiganticMinecraft
              allow_assign_grafana_admin: true
              role_attribute_path: contains(groups[*], '@GiganticMinecraft/onp-admin-proxmox') && 'GrafanaAdmin' || 'Viewer'
            security:
              cookie_secure: true
              strict_transport_security: true
              content_security_policy: true
            users:
              viewers_can_edit: true
          deploymentStrategy:
            type: Recreate
          envValueFrom:
            MARIADB_MONITORING_PASSWORD:
              secretKeyRef:
                name: mariadb-monitoring-password
                key: monitoring-password
          envFromSecret: "grafana-github-oauth-app-secret"
          persistence:
            enabled: true
            size: 10Gi
          datasources:
            datasources.yaml:
              apiVersion: 1
              datasources:
                - name: Prometheus
                  type: prometheus
                  url: http://prometheus-kube-prometheus-prometheus:9090
                  isDefault: true
                - name: Loki
                  type: loki
                  url: http://loki-gateway
                  isDefault: false
                - name: Pyroscope
                  type: grafana-pyroscope-datasource
                  access: proxy
                  url: http://pyroscope:4040
                  isDefault: false
                  jsonData:
                    minStep: '15s'
                - name: Tempo
                  type: tempo
                  access: proxy
                  url: http://tempo:3200
                  isDefault: false
                  jsonData:
                    tracesToLogsV2:
                      datasourceUid: Loki
                      tags: ['job', 'instance', 'pod', 'namespace']
                      filterByTraceID: true
                      filterBySpanID: false
                      spanStartTimeShift: '-1h'
                      spanEndTimeShift: '1h'
                      customQuery: true
                      query: 'method="$${__span.tags.method}"'
                    tracesToMetrics:
                      datasourceUid: Prometheus
                      tags: [{ key: 'service.name', value: 'service' }, { key: 'job' }]
                      queries:
                        - name: 'Sample query'
                          query: 'sum(rate(traces_spanmetrics_latency_bucket{$$__tags}[5m]))'
                    tracesToProfiles:
                      datasourceUid: Pyroscope
                      tags: ['job', 'instance', 'pod', 'namespace']
                      profileTypeId: 'process_cpu:cpu:nanoseconds:cpu:nanoseconds'
                      customQuery: true
                      query: 'method="$${__span.tags.method}"'
                    serviceMap:
                      datasourceUid: 'prometheus'
                    nodeGraph:
                      enabled: true
                    search:
                      hide: false
                    traceQuery:
                      timeShiftEnabled: true
                      spanStartTimeShift: '-1h'
                      spanEndTimeShift: '1h'
                    spanBar:
                      type: 'Tag'
                      tag: 'http.path'
                - name: MariaDB
                  type: mysql
                  url: mariadb.seichi-minecraft:3306
                  isDefault: false
                  user: monitoring
                  secureJsonData:
                    password: ${MARIADB_MONITORING_PASSWORD}
        prometheus:
          thanosService:
            enabled: true
          thanosServiceMonitor:
            enabled: true
            labels:
              release: prometheus
          prometheusSpec:
            enableOTLPReceiver: true
            thanos:
              objectStorageConfig:
                existingSecret:
                  name: garage-thanos-credentials
                  key: objstore.yml
            storageSpec:
              volumeClaimTemplate:
                spec:
                  resources:
                    requests:
                      storage: 300Gi
            resources:
              requests:
                memory: 2Gi
            retention: 180d
            retentionSize: "270GB"
            additionalScrapeConfigs:
            - job_name: 'containerd'
              scheme: http
              metrics_path: '/v1/metrics'
              kubernetes_sd_configs:
              - role: node
              relabel_configs:
              - source_labels: [__address__]
                regex: '([^:]+)(?::\d+)?'
                target_label: __address__
                replacement: '${1}:1338'
              - source_labels: [__meta_kubernetes_node_name]
                target_label: node
              metric_relabel_configs:
              - source_labels: [__name__]
                regex: 'grpc_.*'
                action: drop
        additionalPrometheusRulesMap:
          resource-usage:
            groups:
              - name: resource-usage
                interval: 1m
                rules:
                  - record: namespace:container_memory_working_set_bytes:sum
                    expr: sum by (namespace) (container_memory_working_set_bytes{container!=""})
                  - record: namespace:container_cpu_usage_seconds:sum_rate5m
                    expr: sum by (namespace) (rate(container_cpu_usage_seconds_total{container!=""}[5m]))
                  - record: node:node_memory_utilisation:ratio
                    expr: 1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes
                  - record: node:node_cpu_utilisation:avg5m
                    expr: 1 - avg by (node) (rate(node_cpu_seconds_total{mode="idle"}[5m]))
        alertmanager:
          enabled: false
        kubeApiServer:
          serviceMonitor:
            metricRelabelings:
              - sourceLabels: [__name__]
                regex: 'apiserver_request_body_size_bytes_bucket'
                action: drop
              - sourceLabels: [__name__]
                regex: 'apiserver_watch_(cache_read_wait|list_duration|events_sizes)_seconds_bucket'
                action: drop
        kubeProxy:
          enabled: false
        kubeEtcd:
          endpoints:
            - 192.168.32.11
            - 192.168.32.12
            - 192.168.32.13
          service:
            enabled: true
            port: 2381
            targetPort: 2381
  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: grafana-dashboards-kubernetes
  namespace: argocd
  labels:
    app.kubernetes.io/name: grafana-dashboards-kubernetes
    app.kubernetes.io/version: HEAD
    app.kubernetes.io/managed-by: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  project: cluster-wide-apps
  source:
    path: ./
    repoURL: https://github.com/dotdc/grafana-dashboards-kubernetes
    targetRevision: HEAD
  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    ## https://argo-cd.readthedocs.io/en/stable/user-guide/auto_sync
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - ServerSideApply=true
