apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: loki
  namespace: argocd
  finalizers:
    - resources-finalizer.argocd.argoproj.io # cascade deletion on this App deletion
spec:
  destination:
    namespace: monitoring
    server: https://kubernetes.default.svc
  project: cluster-wide-apps
  source:
    chart: loki-stack
    repoURL: https://grafana.github.io/helm-charts
    targetRevision: 2.9.11
    helm:
      values: |
        loki:
          persistence:
            enabled: true
            size: 50Gi

          config:
            compactor:
              retention_enabled: true

          serviceMonitor:
            enabled: true
            interval: ""
            additionalLabels:
              release: prometheus
            rules:
              #  Some examples from https://awesome-prometheus-alerts.grep.to/rules.html#loki
              - alert: LokiProcessTooManyRestarts
                expr: changes(process_start_time_seconds{job=~"loki"}[15m]) > 2
                for: 0m
                labels:
                  severity: warning
                annotations:
                  summary: Loki process too many restarts (instance {{ $labels.instance }})
                  description: "A loki process had too many restarts (target {{ $labels.instance }})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: LokiRequestErrors
                expr: 100 * sum(rate(loki_request_duration_seconds_count{status_code=~"5.."}[1m])) by (namespace, job, route) / sum(rate(loki_request_duration_seconds_count[1m])) by (namespace, job, route) > 10
                for: 15m
                labels:
                  severity: critical
                annotations:
                  summary: Loki request errors (instance {{ $labels.instance }})
                  description: "The {{ $labels.job }} and {{ $labels.route }} are experiencing errors\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: LokiRequestPanic
                expr: sum(increase(loki_panic_total[10m])) by (namespace, job) > 0
                for: 5m
                labels:
                  severity: critical
                annotations:
                  summary: Loki request panic (instance {{ $labels.instance }})
                  description: "The {{ $labels.job }} is experiencing {{ printf \"%.2f\" $value }}% increase of panics\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: LokiRequestLatency
                expr: (histogram_quantile(0.99, sum(rate(loki_request_duration_seconds_bucket{route!~"(?i).*tail.*"}[5m])) by (le)))  > 1
                for: 5m
                labels:
                  severity: critical
                annotations:
                  summary: Loki request latency (instance {{ $labels.instance }})
                  description: "The {{ $labels.job }} {{ $labels.route }} is experiencing {{ printf \"%.2f\" $value }}s 99th percentile latency\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
        promtail:
          serviceMonitor:
            enabled: true
            additionalLabels:
              release: prometheus

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
